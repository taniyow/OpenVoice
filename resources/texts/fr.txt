Il y a un an, cette vidéo incroyable de Will Smith mangeant des spaghettis a fait sensation dans le monde entier. Nous, les humains, en avons plaisanté. Nous pouvions facilement dire que c'était faux, et à ce moment-là, personne n'avait vraiment peur. Mais un an plus tard, la technologie de l'IA générative a fait un autre énorme bond en avant. Will Smith mangeant des spaghettis en 2024, ce n'est plus une plaisanterie. Si cela ne se stabilise pas bientôt, cela pourrait mettre nos idoles d'Hollywood hors du marché, et il n'y aurait plus personne pour nous laver le cerveau. Dans la vidéo d'aujourd'hui, nous descendrons plus loin dans la Vallée de l'Étrange et examinerons cinq nouveaux outils d'IA générative que vous pouvez effectivement utiliser aujourd'hui. À la fin de cette vidéo, vous pourrez renvoyer votre photographe, vidéaste, ingénieur du son et programmeur humains. Nous sommes le 17 juin 2024, et vous regardez The Code Report. Il y a quelques mois, OpenAI a présenté Sora et nous a taquiné avec une série de vidéos d'IA. Google a ensuite suivi avec Veeo, qui était également assez impressionnant, mais cette semaine, les Chinois ont dévoilé un nouveau modèle appelé Kling. Ils peuvent générer des vidéos de deux minutes, jusqu'à 30 FPS. C'est incroyablement impressionnant, et sans doute meilleur que Sora. Mais il y a un gros problème avec tous ces modèles. Ils ne sont pas disponibles pour le public. Heureusement, un nouvel outil vient de sortir, appelé Dream Machine de LumaLabs, qui vous permet de créer des clips vidéo relativement réalistes. Je lui ai demandé de montrer deux vieux hommes faisant du yoga, et le résultat est indiscernable de la réalité, sauf bien sûr si vous regardez de très près les doigts. De plus, c'est l'outil utilisé pour générer un Will Smith réaliste mangeant des spaghettis, et bien que ce soit impressionnant, il n'y a vraiment pas d'utilisation pratique ou commerciale pour cet outil pour l'instant. Toute sa compétence se limite à simuler des cauchemars. Avant de passer au sujet suivant, parlons de quelque chose dont vos LLM et modèles d'IA ne peuvent pas se passer : les données. La collecte de données sur le web était autrefois un cauchemar. Il fallait configurer des réseaux de proxies, développer des débloqueurs web pour contourner les CAPTCHAs, faire face aux erreurs de serveur, aux empreintes digitales des navigateurs et à toutes sortes d'autres problèmes. Mais avec des proxies résidentiels et des outils d'automatisation web comme Selenium, Puppeteer et Playwright, vous pouvez scraper le web à grande échelle, sans exploser votre budget. C'est là qu'intervient Bright Data, le sponsor de la vidéo d'aujourd'hui. Ils amènent vos opérations de scrape au niveau supérieur pour une fraction du coût. Avec leur API de Navigateur de Scraping, vous pouvez oublier les proxies et les débloqueurs web. Tout ce dont vous avez besoin pour scraper des données à grande échelle est intégré, rendant vos scrapeurs web imparables. Essayez l'API de Navigateur de Scraping de Bright Data gratuitement dès maintenant avec le lien dans la description. Mais le prochain grand outil d'IA dont vous devez connaître est Stable Diffusion 3 Medium. Les poids du modèle ont été publiés il y a quelques heures, et c'est le modèle open de texte à image le plus avancé à ce jour. Malheureusement, il n'est disponible que sous une licence non commerciale, mais le niveau de qualité est assez étonnant et peut désormais générer du texte de manière fiable à partir de vos prompts. Maintenant, si vous avez actuellement une petite amie IA, je vous recommande vivement de la mettre à jour avec ce nouveau modèle. C'est la personnalité qui compte, mais elle va paraître assez médiocre par rapport à tous vos amis sur ST3. Maintenant, un autre outil qui est réellement utile est ce générateur d'effets sonores de Eleven Labs, la même entreprise qui a conçu ma voix. Tout ce que vous avez à faire est de décrire ce que vous voulez entendre, et il générera plusieurs effets sonores. Voici un exemple de deux résultats différents. Et l'exemple deux. Maintenant, ce que je ne vous ai pas dit, c'est qu'un exemple était réel, et l'autre était généré par IA. Je parie que vous ne pouvez pas sentir la différence, mais maintenant nous devons parler de génération de code. J'ai attendu patiemment que l'IA prenne mon poste de programmeur, mais jusqu'à présent, j'ai été déçu. Cependant, il peut encore y avoir de l'espoir. Il y a quelques semaines, la startup française Mistral a sorti un nouveau modèle appelé CodeStroll. C'est aussi un modèle open, mais il ne peut pas encore être utilisé à des fins commerciales, et il fonctionne extrêmement bien sur les benchmarks de codage comparé à d'autres modèles open. J'ai joué avec sur Ollama, et bien que ce soit extrêmement impressionnant et aussi très rapide, il a encore du mal avec le vieux problème de centrer un div. Maintenant, en ce qui concerne l'IA écrivant du code, il y a deux types de personnes. Il y a des gens comme Devin qui poussent l'IA à son maximum et essaient de faire écrire presque 100% de notre code par l'IA. Ces personnes sont généralement jeunes et naïves, selon les pessimistes de l'IA à l'autre bout du spectre. Ils sont généralement des boomers qui pensent que le code de l'IA est de la pure camelote et n'a pas sa place dans l'industrie. Mais l'opinion optimale se situe probablement quelque part entre les deux. Un autre outil gratuit que vous pouvez utiliser maintenant est Cursor, qui est un fork de VS Code, et l'un des premiers éditeurs de code véritablement axés sur l'IA. Au lieu de mémoriser la syntaxe, donnez-lui le contexte d'une base de code existante ou de la documentation, puis appuyez sur Ctrl-K et écrivez votre code en langage naturel. Et si vous craignez qu'il écrive du code de mauvaise qualité, vous pouvez imposer certaines règles et même faire effectuer une revue de code. C'est comme GitHub Copilot sous stéroïdes. L'IA générative a encore un long chemin à parcourir, mais si j'étais Jada maintenant, je serais très préoccupée par la quantité de progrès réalisés par ces nerds de la science des données au cours de la dernière année seulement. C'était The Code Report. Merci de regarder, et je vous verrai dans le prochain.